{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a385fa8-53d6-480a-aae7-30c012daf709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping datasets as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping rouge-score as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping sacrebleu as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping sentencepiece as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping pandas as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping matplotlib as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "✅ Installed versions: \n",
      " - transformers: 4.42.3 \n",
      " - datasets    : 2.19.1 \n",
      " - peft        : 0.11.1 \n",
      " - accelerate  : 0.33.0\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Environment & installs (RunPod/Colab-safe pins)\n",
    "\n",
    "!pip -q uninstall -y peft transformers accelerate datasets rouge-score sacrebleu sentencepiece pandas matplotlib || true\n",
    "\n",
    "!pip -q install \"transformers==4.42.3\" \"datasets==2.19.1\" \\\n",
    "                \"peft==0.11.1\" \"accelerate==0.33.0\" \\\n",
    "                \"sacrebleu==2.4.2\" \"rouge-score==0.1.2\" \\\n",
    "                \"pandas==2.2.2\" \"matplotlib==3.8.4\" \\\n",
    "                \"sentencepiece==0.2.0\"\n",
    "\n",
    "import os, torch, transformers, datasets, peft, accelerate\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "print(\"✅ Installed versions:\",\n",
    "      \"\\n - transformers:\", transformers.__version__,\n",
    "      \"\\n - datasets    :\", datasets.__version__,\n",
    "      \"\\n - peft        :\", peft.__version__,\n",
    "      \"\\n - accelerate  :\", accelerate.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "820d5dc6-a36f-4f71-8888-590d213ffcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & constants\n",
    "\n",
    "import os, json, time, random, gc, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments, Seq2SeqTrainer,\n",
    "    EarlyStoppingCallback, TrainerCallback, set_seed\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "import sacrebleu\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# ---- Model & data ----\n",
    "BASE_MODEL_ID = \"google/flan-t5-small\"\n",
    "DATASET_ID    = \"cnn_dailymail\"\n",
    "DATASET_CONF  = \"3.0.0\"\n",
    "\n",
    "# ---- Output dirs ----\n",
    "RUN_DIR  = \"outputs/summarizer_lora/cnndm_run\"\n",
    "BEST_DIR = os.path.join(RUN_DIR, \"best_checkpoint\")\n",
    "ART_DIR  = os.path.join(RUN_DIR, \"artifacts\")\n",
    "os.makedirs(BEST_DIR, exist_ok=True)\n",
    "os.makedirs(ART_DIR,  exist_ok=True)\n",
    "\n",
    "# ---- Subset sizes ----\n",
    "TRAIN_N, VAL_N, TEST_N = 6000, 600, 600   # increase/decrease if needed\n",
    "\n",
    "# ---- Sequence lengths ----\n",
    "MAX_SRC_LEN = 512\n",
    "MAX_TGT_LEN = 96   # try 128 later if you want longer summaries\n",
    "\n",
    "# ---- Training schedule ----\n",
    "EPOCHS = 1\n",
    "BATCH  = 1\n",
    "ACCUM  = 8\n",
    "EVAL_STEPS = 75    # ~10 evals across ~750 steps\n",
    "\n",
    "print(\"✅ Setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf7e82a-f8a0-48eb-8e05-f4ef8095cafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset 'cnn_dailymail' config '3.0.0' …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ddc67c790e47169d54b650b26c0794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b6b893e64b4f1b8283ea4382c1c996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8047936833024262a2613ac2f16b5ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cd636c2a2445d0a4d93ae6b700c550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7df150ec19c4b54a0b1bbb4a3bacc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8536d9d2f8044de69626d9373390191e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943caf10d838446cb3a3ce1936fab40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e809828e1646dfa57470540635a3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67f112f5426414fbe5f7fcf14d7b839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 287113\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 13368\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 11490\n",
      "    })\n",
      "})\n",
      "\n",
      "Keys: ['article', 'highlights', 'id']\n",
      "[article][:240]: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in …\n",
      "[highlights]: Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load CNN/DailyMail (v3.0.0) and peek\n",
    "\n",
    "print(f\"Loading dataset '{DATASET_ID}' config '{DATASET_CONF}' …\")\n",
    "raw = load_dataset(DATASET_ID, DATASET_CONF)  # fields: article, highlights, id\n",
    "print(raw)\n",
    "\n",
    "ex = raw[\"train\"][0]\n",
    "print(\"\\nKeys:\", list(ex.keys()))\n",
    "print(\"[article][:240]:\", ex[\"article\"][:240].replace(\"\\n\",\" \"), \"…\")\n",
    "print(\"[highlights]:\", ex[\"highlights\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da69a05-f308-4b39-b257-977cf67b07e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small splits -> train:6000 val:600 test:600\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Build balanced small splits (train/val/test), no overlap\n",
    "\n",
    "def text_len(ds, i):\n",
    "    return len(ds[i].get(\"article\") or \"\")\n",
    "\n",
    "def balanced_sample(ds, n, seed=SEED):\n",
    "    n = min(n, len(ds))\n",
    "    if n <= 0:\n",
    "        return ds.select([])\n",
    "    lengths = np.array([text_len(ds, i) for i in range(len(ds))])\n",
    "    q1, q2 = np.quantile(lengths, [0.33, 0.66])\n",
    "    idx_s = np.where(lengths <= q1)[0].tolist()\n",
    "    idx_m = np.where((lengths > q1) & (lengths <= q2))[0].tolist()\n",
    "    idx_l = np.where(lengths > q2)[0].tolist()\n",
    "    rng = random.Random(seed)\n",
    "    take = []\n",
    "    for bucket, k in zip([idx_s, idx_m, idx_l], [n//3, n//3, n - 2*(n//3)]):\n",
    "        take.extend(rng.sample(bucket, min(k, len(bucket))))\n",
    "    rng.shuffle(take)\n",
    "    return ds.select(take[:n])\n",
    "\n",
    "train_small = balanced_sample(raw[\"train\"],      TRAIN_N, seed=SEED)\n",
    "val_small   = balanced_sample(raw[\"validation\"], VAL_N,   seed=SEED+1)\n",
    "test_small  = balanced_sample(raw[\"test\"],       TEST_N,  seed=SEED+2)\n",
    "\n",
    "print(f\"Small splits -> train:{len(train_small)} val:{len(val_small)} test:{len(test_small)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc8c1a4d-85e0-4f04-8c21-1f8328c4ca17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70aadfe8db24298a93cd546686ffb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318218d44ade4eb6bca0be628bc7c64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c743a5e4af0348d68148a0bcdd280838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4180f3adf7264bc29be17a51ae590e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839be14cf30c4a69b3bbaa4e8acb64e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0325458e8cf64d1c8e5f10b31a0af7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After format/filter -> train:6000 val:600 test:600\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Formatting (prefix 'summarize:' + label)\n",
    "\n",
    "def fmt(ex):\n",
    "    article = (ex.get(\"article\") or \"\").strip()\n",
    "    summary = (ex.get(\"highlights\") or \"\").strip()\n",
    "    return {\n",
    "        \"input_text\": f\"summarize: {article}\",\n",
    "        \"label_text\": summary\n",
    "    }\n",
    "\n",
    "fmt_train = train_small.map(fmt, remove_columns=train_small.column_names)\n",
    "fmt_val   = val_small.map(fmt,   remove_columns=val_small.column_names)\n",
    "fmt_test  = test_small.map(fmt,  remove_columns=test_small.column_names)\n",
    "\n",
    "# Filter empty\n",
    "def ok(e): return bool(e[\"input_text\"].strip()) and bool(e[\"label_text\"].strip())\n",
    "fmt_train = fmt_train.filter(ok)\n",
    "fmt_val   = fmt_val.filter(ok)\n",
    "fmt_test  = fmt_test.filter(ok)\n",
    "\n",
    "print(\"After format/filter ->\",\n",
    "      f\"train:{len(fmt_train)} val:{len(fmt_val)} test:{len(fmt_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b358f7-6c95-483b-9fad-d4e7155a4a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df292d330ce47d98b952f8d2d474c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80fd2c222f54ac6aa6d660aa338ed48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a273365c11e4503af2b6a47dc93a777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c24f0591124da685acb4d165bf9f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd55a47a72c044689eb292d47cb9b1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b632854907e453a82a134cf26993cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fda9560e7a24fa9846cfa8ca67c48a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132f21007b9b4b06a5ce6bf476c58397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc40adbe648246ceb08623b682f75e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b7fb6f29424aeb981d8288144fe7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenized: 6000 600 600\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Tokenization (pad fixed; mask label pads with -100)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n",
    "\n",
    "def tok(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"input_text\"],\n",
    "        max_length=MAX_SRC_LEN,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    tgt = tokenizer(\n",
    "        text_target=batch[\"label_text\"],\n",
    "        max_length=MAX_TGT_LEN,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    pad_id = tokenizer.pad_token_id\n",
    "    labels = [[t if t != pad_id else -100 for t in seq] for seq in tgt[\"input_ids\"]]\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "tok_train = fmt_train.map(tok, batched=True, remove_columns=fmt_train.column_names)\n",
    "tok_val   = fmt_val.map(  tok, batched=True, remove_columns=fmt_val.column_names)\n",
    "tok_test  = fmt_test.map( tok, batched=True, remove_columns=fmt_test.column_names)\n",
    "\n",
    "# Safety: drop rows with all -100 labels\n",
    "def has_label_tokens(e): return any(t != -100 for t in e[\"labels\"])\n",
    "tok_train = tok_train.filter(has_label_tokens)\n",
    "tok_val   = tok_val.filter(has_label_tokens)\n",
    "tok_test  = tok_test.filter(has_label_tokens)\n",
    "\n",
    "print(\"✅ Tokenized:\", len(tok_train), len(tok_val), len(tok_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f4460f-3d63-46af-a158-e6bf7e001f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271abc430f044d969d22b910162e9743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c73345a6fd445d869df6d9cd5ce56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f836a25d26495c8e5b19d513ad053a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,376,256 || all params: 78,337,408 || trainable%: 1.7568\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Model + LoRA (stable FP32)\n",
    "\n",
    "base = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL_ID)  # FP32\n",
    "base.config.use_cache = False\n",
    "base.gradient_checkpointing_enable()\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=16, lora_alpha=32, lora_dropout=0.05,\n",
    "    target_modules=[\"q\",\"k\",\"v\",\"o\"],\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")\n",
    "model = get_peft_model(base, lora_cfg)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e554926e-96f7-4578-a41d-82f50dad2614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Collator, callbacks, robust metrics\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "class MetricsRecorder(TrainerCallback):\n",
    "    def __init__(self): self.rows = []\n",
    "    def on_log(self, args, state, control, logs=None, **kw):\n",
    "        if not logs: return\n",
    "        row = {\"step\": int(state.global_step)}\n",
    "        for k, v in logs.items():\n",
    "            if k.startswith((\"loss\",\"eval_\",\"learning_rate\")):\n",
    "                row[k] = float(v) if isinstance(v, (int,float)) else v\n",
    "        self.rows.append(row)\n",
    "\n",
    "class EmptyCacheCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "recorder = MetricsRecorder()\n",
    "\n",
    "# Robust metrics (handles logits vs ids)\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    preds = getattr(eval_pred, \"predictions\", None)\n",
    "    labels = getattr(eval_pred, \"label_ids\", None)\n",
    "    if preds is None or labels is None:\n",
    "        preds, labels = eval_pred\n",
    "\n",
    "    if isinstance(preds, torch.Tensor): preds = preds.detach().cpu().numpy()\n",
    "    if isinstance(labels, torch.Tensor): labels = labels.detach().cpu().numpy()\n",
    "\n",
    "    arr = np.asarray(preds, dtype=object)\n",
    "    if arr.dtype not in (np.int64, np.int32):\n",
    "        try:\n",
    "            preds = np.argmax(arr, axis=-1) if getattr(arr, \"ndim\", 0) == 3 else \\\n",
    "                    np.array([np.asarray(p).argmax(-1) for p in arr], dtype=np.int64)\n",
    "        except Exception:\n",
    "            preds = np.asarray(preds).astype(np.int64, copy=False)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds  = tokenizer.batch_decode(preds,  skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds  = [p.strip() for p in decoded_preds]\n",
    "    decoded_labels = [l.strip() for l in decoded_labels]\n",
    "\n",
    "    bleu = sacrebleu.corpus_bleu(decoded_preds, [decoded_labels]).score\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\",\"rouge2\",\"rougeLsum\"], use_stemmer=True)\n",
    "    r1=r2=rl=0.0\n",
    "    n = len(decoded_labels)\n",
    "    for ref, pred in zip(decoded_labels, decoded_preds):\n",
    "        s = scorer.score(ref, pred)\n",
    "        r1 += s[\"rouge1\"].fmeasure\n",
    "        r2 += s[\"rouge2\"].fmeasure\n",
    "        rl += s[\"rougeLsum\"].fmeasure\n",
    "    r1, r2, rl = 100*r1/n, 100*r2/n, 100*rl/n\n",
    "\n",
    "    return {\"bleu\": bleu, \"rouge1_f\": r1, \"rouge2_f\": r2, \"rougeL_f\": rl}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c863c93b-4dd6-403d-81c7-17086e3872d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: TrainingArguments (stable; frequent evals; early-stop on eval_loss)\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=RUN_DIR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH,\n",
    "    per_device_eval_batch_size=BATCH,\n",
    "    gradient_accumulation_steps=ACCUM,\n",
    "\n",
    "    # Stability knobs for T5\n",
    "    optim=\"adafactor\",\n",
    "    learning_rate=1e-4,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.0,\n",
    "    max_grad_norm=0.3,\n",
    "    label_smoothing_factor=0.1,\n",
    "\n",
    "    logging_steps=25,\n",
    "\n",
    "    # Use alias you prefer:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=EVAL_STEPS,\n",
    "\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=EVAL_STEPS,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    # ✅ Use eval_loss for best checkpoint (more stable than early ROUGE)\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "\n",
    "    # memory-safe evaluation during training (greedy by default)\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=MAX_TGT_LEN,\n",
    "    generation_num_beams=1,\n",
    "    eval_accumulation_steps=64,\n",
    "    group_by_length=True,\n",
    "\n",
    "    include_inputs_for_metrics=False,\n",
    "    report_to=\"none\",\n",
    "\n",
    "    # FP32 training\n",
    "    fp16=False, bf16=False,\n",
    "\n",
    "    dataloader_num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e557644-eeac-4da7-b85b-eb95bf6ccfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting training…\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 1:32:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Rouge1 F</th>\n",
       "      <th>Rouge2 F</th>\n",
       "      <th>Rougel F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>4.090800</td>\n",
       "      <td>3.837052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.955600</td>\n",
       "      <td>3.629176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.809600</td>\n",
       "      <td>3.567265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.854400</td>\n",
       "      <td>3.525495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>3.799000</td>\n",
       "      <td>3.502305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.748400</td>\n",
       "      <td>3.487947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>3.805600</td>\n",
       "      <td>3.479552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.761700</td>\n",
       "      <td>3.475936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>3.734400</td>\n",
       "      <td>3.475637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.866800</td>\n",
       "      <td>3.474071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ Training done in 92.2 min\n",
      "Best checkpoint: outputs/summarizer_lora/cnndm_run/checkpoint-750\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Trainer & Train\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple): logits = logits[0]\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "trainer_kwargs = dict(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tok_train,\n",
    "    eval_dataset=tok_val,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[recorder, EarlyStoppingCallback(early_stopping_patience=8), EmptyCacheCallback()],\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")\n",
    "\n",
    "# Prefer processing_class (new) -> fallback to tokenizer (older stacks)\n",
    "try:\n",
    "    trainer = Seq2SeqTrainer(processing_class=tokenizer, **trainer_kwargs)\n",
    "except TypeError:\n",
    "    trainer = Seq2SeqTrainer(tokenizer=tokenizer, **trainer_kwargs)\n",
    "\n",
    "print(\"🚀 Starting training…\")\n",
    "t0 = time.time()\n",
    "trainer.train()\n",
    "print(f\"⏱️ Training done in {(time.time()-t0)/60:.1f} min\")\n",
    "print(\"Best checkpoint:\", trainer.state.best_model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3247de4-5045-4ed0-8cb4-dced23a60813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving best LoRA adapters…\n",
      "✅ Saved to: outputs/summarizer_lora/cnndm_run/best_checkpoint\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Save best LoRA adapters + tokenizer\n",
    "\n",
    "print(\"💾 Saving best LoRA adapters…\")\n",
    "trainer.save_model(BEST_DIR)\n",
    "tokenizer.save_pretrained(BEST_DIR)\n",
    "print(\"✅ Saved to:\", BEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0410ca6-b8ae-4cce-a42d-19dce82da0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Metrics CSV: outputs/summarizer_lora/cnndm_run/artifacts/training_metrics.csv\n",
      "🖼️ Saved: outputs/summarizer_lora/cnndm_run/artifacts/loss_curve_clean.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Clean loss plots (train + eval), saved to ART_DIR\n",
    "\n",
    "metrics_df = pd.DataFrame(recorder.rows).drop_duplicates(\"step\").sort_values(\"step\")\n",
    "csv_path = os.path.join(ART_DIR, \"training_metrics.csv\")\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "print(\"📈 Metrics CSV:\", csv_path)\n",
    "\n",
    "import numpy as np\n",
    "def series_xy(frame, ycol):\n",
    "    if ycol not in frame.columns: return None, None\n",
    "    d = frame[[\"step\", ycol]].dropna()\n",
    "    if d.empty: return None, None\n",
    "    return d[\"step\"].astype(int).values, d[ycol].astype(float).values\n",
    "\n",
    "# Plot: Loss\n",
    "fig, ax = plt.subplots(figsize=(8,4.5))\n",
    "\n",
    "x_tr, y_tr = series_xy(metrics_df, \"loss\")\n",
    "if x_tr is not None:\n",
    "    ax.plot(x_tr, y_tr, alpha=0.35, label=\"train_loss\")\n",
    "    tr_df = pd.DataFrame({\"step\": x_tr, \"loss\": y_tr})\n",
    "    tr_df[\"ema\"] = tr_df[\"loss\"].ewm(span=10, adjust=False).mean()\n",
    "    ax.plot(tr_df[\"step\"], tr_df[\"ema\"], label=\"train_loss (EMA)\")\n",
    "\n",
    "x_ev, y_ev = series_xy(metrics_df, \"eval_loss\")\n",
    "if x_ev is not None:\n",
    "    ax.plot(x_ev, y_ev, marker=\"o\", linewidth=1.5, label=\"eval_loss\")\n",
    "\n",
    "ax.set_title(\"Loss vs Steps\")\n",
    "ax.set_xlabel(\"Step\"); ax.set_ylabel(\"Loss\")\n",
    "ax.grid(True, alpha=0.2); ax.legend()\n",
    "loss_png = os.path.join(ART_DIR, \"loss_curve_clean.png\")\n",
    "plt.tight_layout(); plt.savefig(loss_png, dpi=150); plt.close()\n",
    "print(\"🖼️ Saved:\", loss_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13da0058-22e4-49a9-a9d4-7234eaf44165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running final GREEDY evaluation on Validation and Test sets...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2400' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 38:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 FINAL VAL (greedy): {'eval_loss': 3.4740705490112305, 'eval_bleu': 0.0, 'eval_rouge1_f': 0.0, 'eval_rouge2_f': 0.0, 'eval_rougeL_f': 0.0, 'eval_runtime': 537.5496, 'eval_samples_per_second': 1.116, 'eval_steps_per_second': 1.116, 'epoch': 1.0}\n",
      "📊 FINAL TEST (greedy): {'eval_loss': 3.4630119800567627, 'eval_bleu': 0.0, 'eval_rouge1_f': 0.0, 'eval_rouge2_f': 0.0, 'eval_rougeL_f': 0.0, 'eval_runtime': 488.2553, 'eval_samples_per_second': 1.229, 'eval_steps_per_second': 1.229, 'epoch': 1.0}\n",
      "\n",
      "Running BEAM evaluation (num_beams=4, min_new_tokens=16)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n",
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 VAL (beam=4): {'beam4_loss': 3.4740705490112305, 'beam4_bleu': 0.0, 'beam4_rouge1_f': 0.0, 'beam4_rouge2_f': 0.0, 'beam4_rougeL_f': 0.0, 'beam4_runtime': 640.6021, 'beam4_samples_per_second': 0.937, 'beam4_steps_per_second': 0.937, 'epoch': 1.0}\n",
      "🔁 TEST (beam=4): {'beam4_test_loss': 3.4630119800567627, 'beam4_test_bleu': 0.0, 'beam4_test_rouge1_f': 0.0, 'beam4_test_rouge2_f': 0.0, 'beam4_test_rougeL_f': 0.0, 'beam4_test_runtime': 655.0492, 'beam4_test_samples_per_second': 0.916, 'beam4_test_steps_per_second': 0.916, 'epoch': 1.0}\n",
      "💾 Saved run summary to ART_DIR.\n",
      "🖼️ Saved: outputs/summarizer_lora/cnndm_run/artifacts/final_val_metrics_beam4.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Final eval (greedy) + Beam eval (better summaries) + save results\n",
    "\n",
    "print(\"Running final GREEDY evaluation on Validation and Test sets...\")\n",
    "final_val  = trainer.evaluate(eval_dataset=tok_val)   # keys: eval_*\n",
    "final_test = trainer.evaluate(eval_dataset=tok_test)\n",
    "print(\"📊 FINAL VAL (greedy):\", final_val)\n",
    "print(\"📊 FINAL TEST (greedy):\", final_test)\n",
    "\n",
    "print(\"\\nRunning BEAM evaluation (num_beams=4, min_new_tokens=16)…\")\n",
    "beam_val = trainer.evaluate(\n",
    "    eval_dataset=tok_val,\n",
    "    metric_key_prefix=\"beam4\",\n",
    "    num_beams=4,\n",
    "    max_length=MAX_TGT_LEN,\n",
    "    min_new_tokens=16,\n",
    "    no_repeat_ngram_size=3,\n",
    "    length_penalty=1.0,\n",
    "    early_stopping=True,\n",
    ")\n",
    "beam_test = trainer.evaluate(\n",
    "    eval_dataset=tok_test,\n",
    "    metric_key_prefix=\"beam4_test\",\n",
    "    num_beams=4,\n",
    "    max_length=MAX_TGT_LEN,\n",
    "    min_new_tokens=16,\n",
    "    no_repeat_ngram_size=3,\n",
    "    length_penalty=1.0,\n",
    "    early_stopping=True,\n",
    ")\n",
    "print(\"🔁 VAL (beam=4):\", beam_val)\n",
    "print(\"🔁 TEST (beam=4):\", beam_test)\n",
    "\n",
    "# Save JSON summary for report\n",
    "summary = {\n",
    "    \"dataset\": {\"id\": DATASET_ID, \"config\": DATASET_CONF,\n",
    "                \"train_n\": len(tok_train), \"val_n\": len(tok_val), \"test_n\": len(tok_test)},\n",
    "    \"model\": BASE_MODEL_ID,\n",
    "    \"peft_lora\": {\"r\": 16, \"alpha\": 32, \"dropout\": 0.05, \"targets\": [\"q\",\"k\",\"v\",\"o\"]},\n",
    "    \"seq_lens\": {\"src\": MAX_SRC_LEN, \"tgt\": MAX_TGT_LEN},\n",
    "    \"training\": {\n",
    "        \"epochs\": EPOCHS, \"batch_per_device\": BATCH, \"grad_accum\": ACCUM,\n",
    "        \"optim\": \"adafactor\", \"lr\": 1e-4, \"warmup_ratio\": 0.06,\n",
    "        \"label_smoothing\": 0.1, \"max_grad_norm\": 0.3,\n",
    "        \"best_checkpoint\": trainer.state.best_model_checkpoint\n",
    "    },\n",
    "    \"final_val_greedy\": final_val,\n",
    "    \"final_test_greedy\": final_test,\n",
    "    \"final_val_beam4\": beam_val,\n",
    "    \"final_test_beam4\": beam_test,\n",
    "    \"artifacts\": {\n",
    "        \"metrics_csv\": os.path.join(ART_DIR, \"training_metrics.csv\"),\n",
    "        \"loss_curve_png\": os.path.join(ART_DIR, \"loss_curve_clean.png\"),\n",
    "        \"best_adapters_dir\": BEST_DIR\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(ART_DIR, \"run_summary.json\"), \"w\") as f: json.dump(summary, f, indent=2)\n",
    "with open(os.path.join(ART_DIR, \"run_summary.txt\"), \"w\") as f: f.write(json.dumps(summary, indent=2))\n",
    "print(\"💾 Saved run summary to ART_DIR.\")\n",
    "\n",
    "# Bar chart for final BEAM metrics (VAL)\n",
    "vals = {\n",
    "    \"BLEU\":      beam_val.get(\"beam4_bleu\", 0.0),\n",
    "    \"ROUGE-1 F\": beam_val.get(\"beam4_rouge1_f\", 0.0),\n",
    "    \"ROUGE-2 F\": beam_val.get(\"beam4_rouge2_f\", 0.0),\n",
    "    \"ROUGE-L F\": beam_val.get(\"beam4_rougeL_f\", 0.0),\n",
    "}\n",
    "plt.figure(figsize=(6.5,4))\n",
    "plt.bar(list(vals.keys()), list(vals.values()))\n",
    "plt.title(\"Final Validation Metrics (beam=4, min_new_tokens=16)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.tight_layout()\n",
    "bar_png = os.path.join(ART_DIR, \"final_val_metrics_beam4.png\")\n",
    "plt.savefig(bar_png, dpi=150)\n",
    "plt.close()\n",
    "print(\"🖼️ Saved:\", bar_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01547348-2a86-4313-a4d6-8dd78bb7d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Sample predictions saved: outputs/summarizer_lora/cnndm_run/artifacts/sample_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Sample predictions (beam=4) for qualitative examples\n",
    "\n",
    "def gen_batch(texts, max_len=MAX_TGT_LEN, num_beams=4, min_new_tokens=16):\n",
    "    mdl = trainer.model.eval()\n",
    "    enc = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_SRC_LEN)\n",
    "    if torch.cuda.is_available():\n",
    "        mdl.cuda(); enc = {k: v.cuda() for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        out = mdl.generate(\n",
    "            **enc, num_beams=num_beams, max_length=max_len,\n",
    "            min_new_tokens=min_new_tokens, no_repeat_ngram_size=3,\n",
    "            length_penalty=1.0, early_stopping=True\n",
    "        )\n",
    "    return tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "\n",
    "n = min(20, len(fmt_val))\n",
    "sample_inputs  = [fmt_val[i][\"input_text\"] for i in range(n)]\n",
    "sample_targets = [fmt_val[i][\"label_text\"] for i in range(n)]\n",
    "preds = gen_batch(sample_inputs)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"input_preview\": [s[:280].replace(\"\\n\",\" \") + (\"...\" if len(s)>280 else \"\") for s in sample_inputs],\n",
    "    \"target_summary\": sample_targets,\n",
    "    \"predicted_summary\": [p.strip() for p in preds]\n",
    "})\n",
    "pred_csv = os.path.join(ART_DIR, \"sample_predictions.csv\")\n",
    "pred_df.to_csv(pred_csv, index=False)\n",
    "print(\"🧪 Sample predictions saved:\", pred_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55176a3d-851f-429f-a4f9-04ce0b16276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged model saved to: outputs/summarizer_lora/cnndm_run/merged_full_model\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Merge LoRA into base (single folder model)\n",
    "\n",
    "merge_dir = os.path.join(RUN_DIR, \"merged_full_model\")\n",
    "os.makedirs(merge_dir, exist_ok=True)\n",
    "\n",
    "base_m = AutoModelForSeq2SeqLM.from_pretrained(BASE_MODEL_ID)\n",
    "peft_m = PeftModel.from_pretrained(base_m, BEST_DIR)\n",
    "peft_m = peft_m.merge_and_unload()\n",
    "peft_m.config.use_cache = True\n",
    "peft_m.save_pretrained(merge_dir, safe_serialization=True)\n",
    "tokenizer.save_pretrained(merge_dir)\n",
    "print(\"✅ Merged model saved to:\", merge_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccfab488-4ef9-4177-b2ff-e8efe4c94323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Wrote manifest: outputs/summarizer_lora/cnndm_run/artifacts/manifest.json\n",
      "📦 ZIP created at: /workspace/summarizer_all_artifacts.zip\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Zip ALL artifacts (models + plots + logs) for download\n",
    "\n",
    "import shutil, pathlib\n",
    "\n",
    "# Create a manifest for convenience\n",
    "manifest = {\n",
    "    \"run_dir\": RUN_DIR,\n",
    "    \"adapters_dir\": BEST_DIR,\n",
    "    \"merged_model_dir\": os.path.join(RUN_DIR, \"merged_full_model\"),\n",
    "    \"artifacts_dir\": ART_DIR,\n",
    "    \"files\": {\n",
    "        \"metrics_csv\": os.path.join(ART_DIR, \"training_metrics.csv\"),\n",
    "        \"loss_curve_png\": os.path.join(ART_DIR, \"loss_curve_clean.png\"),\n",
    "        \"final_val_metrics_beam4_png\": os.path.join(ART_DIR, \"final_val_metrics_beam4.png\"),\n",
    "        \"sample_predictions_csv\": os.path.join(ART_DIR, \"sample_predictions.csv\"),\n",
    "        \"run_summary_json\": os.path.join(ART_DIR, \"run_summary.json\"),\n",
    "        \"run_summary_txt\": os.path.join(ART_DIR, \"run_summary.txt\"),\n",
    "    },\n",
    "}\n",
    "with open(os.path.join(ART_DIR, \"manifest.json\"), \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "print(\"🧾 Wrote manifest:\", os.path.join(ART_DIR, \"manifest.json\"))\n",
    "\n",
    "zip_path = shutil.make_archive(\"summarizer_all_artifacts\", \"zip\", root_dir=RUN_DIR)\n",
    "print(\"📦 ZIP created at:\", zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdac014-905e-41c2-90b2-19f8550cbfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
