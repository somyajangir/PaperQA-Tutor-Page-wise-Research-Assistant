# ğŸ“š PaperQA Section Tutor â€” IIT Jodhpur

<div align="center">

**An intelligent AI agent for interactive research paper learning**

*Study research papers page-by-page with AI-powered explanations, Q&A, and personalized quizzes*

---

**ğŸ‘¨â€ğŸ“ Author:** Somya Jangir (B23CI1036)  
**ğŸ›ï¸ Department:** Civil and Infrastructure Engineering  
**ğŸ« Institution:** IIT Jodhpur

---

</div>

## ğŸ¯ Overview

An interactive AI agent that transforms how you study research papers:

- ğŸ“– **Page-by-page explanations** in clean, structured English
- â“ **Intelligent Q&A** with RAG over uploaded PDFs (with citations)
- ğŸ§ª **Quiz generation** with smart grading (Correct / Partial / Incorrect)
- ğŸ¤– **Local summarizer** using fine-tuned Gemma-3-270M (LoRA) â€” runs offline, no API required

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ“„ **PDF Ingestion** | PyMuPDF â†’ Structured Page Plan |
| ğŸ” **RAG System** | sentence-transformers `all-MiniLM-L6-v2` + FAISS with citations |
| ğŸ“ **Page Tutor** | Gemini 2.5 Flash Lite â€” *Conceptual Summary / Breakdown / Key Terms* |
| ğŸ“ **Local Summary** | Fine-tuned Gemma-3-270M â€” 3-4+ sentence summaries, offline |
| ğŸ¯ **Quiz Generation** | Gemini â†’ Smart Grading with detailed feedback |
| ğŸ”Š **TTS Playback** | Audio explanations and summaries |
| ğŸ“Š **Lightweight Logging** | JSONL event tracking (disabled for submission) |

---

## ğŸ—ï¸ Repository Structure

```
.
â”œâ”€ ğŸ¤– agent/
â”‚   â”œâ”€ embeddings.py          # Shared singleton embedding model (MiniLM-L6-v2)
â”‚   â”œâ”€ ingestor.py            # PyMuPDF page extractor
â”‚   â”œâ”€ indexer.py             # Word-chunker + FAISS RAG index
â”‚   â”œâ”€ page_qa.py             # Per-page QA agent (retrieval + Gemini synthesis)
â”‚   â”œâ”€ explainer.py           # Page explainer (Gemini 2.5 Flash Lite)
â”‚   â”œâ”€ qg_generator.py        # Quiz generator (Gemini â†’ JSON)
â”‚   â”œâ”€ evaluator.py           # Grader (Gemini â†’ feedback)
â”‚   â”œâ”€ summarizer.py          # ğŸŒŸ Fine-tuned Gemma-3-270M local summarizer
â”‚   â””â”€ logger.py              # JSONL event logging
â”‚
â”œâ”€ ğŸ–¥ï¸ ui/
â”‚   â””â”€ app.py                 # Streamlit app: Viewer + Page Tutor + RAG
â”‚
â”œâ”€ ğŸ“Š Finetuning results, graphs and samples/
â”‚   â”œâ”€ loss_curve.png
â”‚   â”œâ”€ val_metrics_beam4.png
â”‚   â”œâ”€ training_metrics.csv
â”‚   â”œâ”€ sample_predictions.csv
â”‚   â””â”€ run_summary.json       # Gemma-3-270M LoRA run (CNN/DM 3.0.0)
â”‚
â”œâ”€ ğŸ§  Gemma 3 Finetuning.py   # Fine-tuning notebook/script (RunPod/Colab)
â”œâ”€ ğŸ‹ï¸ merged_full_model/      # Model weights directory
â”œâ”€ ğŸ“‹ requirements.txt
â””â”€ ğŸ“š docs/
    â”œâ”€ ARCHITECTURE.md
    â””â”€ DATA_SCIENCE_REPORT.md
```

> **ğŸ“ Note:** The **"Finetuning results, graphs and samples"** folder contains all artifacts produced during fine-tuning (plots, metrics, samples, run summary).

---

## ğŸš€ Quick Start Guide

### 1ï¸âƒ£ Environment Setup

```bash
# Create virtual environment
python -m venv .venv

# Activate environment
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ API Configuration

Create a `.env` file in the repository root:

```bash
GOOGLE_API_KEY=your_gemini_key_here

# Optional: Custom model path
# SUMMARIZER_MODEL_DIR=/absolute/path/to/merged_full_model
```

### 3ï¸âƒ£ Local Summarizer Weights

**Preferred method:** Download the **merged Gemma-3-270M** folder and place it at:

```
merged_full_model/
```

Alternatively, set `SUMMARIZER_MODEL_DIR` in your `.env` file.

### 4ï¸âƒ£ Launch Application

```bash
streamlit run ui/app.py
```

---

## ğŸ® How to Use

1. **ğŸ“¤ Upload** a PDF from the sidebar
2. **ğŸ“ Page Tutor** tab â†’ Get explanations + **Local Summary (Gemma-3-270M)** 
3. **â“ Ask Questions** â†’ Page-scoped inquiries with intelligent responses
4. **ğŸ§ª Generate Quiz** â†’ Test your understanding with auto-graded questions
5. **ğŸ” RAG Tab** â†’ Ask about the entire document with evidence citations

---

## ğŸ§ª Evaluation & Performance

- **ğŸ“Š Summarizer (Gemma-3-270M LoRA):** Evaluated on CNN/DailyMail 3.0.0 with ROUGE/BLEU metrics
- **ğŸ¯ Agent Performance:** Quiz grader provides **Correct/Partial/Incorrect** classifications with constructive feedback
- **ğŸ“ˆ Results:** See `Finetuning results, graphs and samples/run_summary.json` for detailed metrics

---

## ğŸ“œ Important Notes

### ğŸ” Security & Ethics
- âš ï¸ **Never commit API keys or HF tokens**
- ğŸ“¦ **Large model weights are not committed** (see Local summarizer weights section)
- ğŸ“ **Academic Integrity:** Use as a study aid and cite sources appropriately

---

